{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install xlsxwriter"
      ],
      "metadata": {
        "id": "2q4O5Ces0UIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo6kJG2sq3ZA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import calendar\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise Exploratória"
      ],
      "metadata": {
        "id": "C_hlg-cTUVYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tratamento de dados"
      ],
      "metadata": {
        "id": "YdTCadkA2b2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_leap_year(year):\n",
        "    return calendar.isleap(year)"
      ],
      "metadata": {
        "id": "Q3xFvtFPiW9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_rows(df):\n",
        "  return len(df)"
      ],
      "metadata": {
        "id": "ZsyB13MD228o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_columns(df):\n",
        "  return len(df.columns)"
      ],
      "metadata": {
        "id": "_mMKt7GN3BiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def date_and_time(df):\n",
        "  df['Data'] = pd.to_datetime(df['Data'])\n",
        "\n",
        "  df['Date'] = df['Data'].dt.date\n",
        "  df['Time'] = df['Data'].dt.time"
      ],
      "metadata": {
        "id": "TTnY0bgz4WFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def duplicates(df):\n",
        "  return df['Data'].duplicated()"
      ],
      "metadata": {
        "id": "N15fx0aH48MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_time_difference(df):\n",
        "  return (time_diff(df)).mean()"
      ],
      "metadata": {
        "id": "QcJsUd-rnZaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_diff(df):\n",
        "  time_diff = df['Data'].diff()\n",
        "  return time_diff[time_diff > pd.Timedelta(0)]"
      ],
      "metadata": {
        "id": "e2y43eyOEVFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_time_difference_per_year(df):\n",
        "  df_copy = df.copy()\n",
        "  df_copy['TimeDiff'] = df_copy['Data'].diff()\n",
        "  df_copy['TimeDiff'] = df_copy['TimeDiff'][df_copy['TimeDiff'] > pd.Timedelta(0)]\n",
        "\n",
        "  df_copy['Year'] = df_copy['Data'].dt.year\n",
        "\n",
        "  return df_copy.groupby('Year')['TimeDiff'].mean()\n"
      ],
      "metadata": {
        "id": "eZT4-C29yVqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_time_difference_per_month(df):\n",
        "  df_copy = df.copy()\n",
        "\n",
        "  df_copy['TimeDiff'] = df['Data'].diff()\n",
        "\n",
        "  df_copy['TimeDiff'] = df_copy['TimeDiff'][df_copy['TimeDiff'] > pd.Timedelta(0)]\n",
        "\n",
        "  df_copy['Year'] = df_copy['Data'].dt.year\n",
        "  df_copy['Month'] = df_copy['Data'].dt.month\n",
        "\n",
        "  return df_copy.groupby(['Year', 'Month'])['TimeDiff'].mean()"
      ],
      "metadata": {
        "id": "XCq19RsU0we-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format(df):\n",
        "  formato = ['Date', 'Time', 'Caudal']\n",
        "  return df[formato]"
      ],
      "metadata": {
        "id": "8lbxa8MIPxYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def has_seconds(df):\n",
        "  df['Time'] = df['Time'].apply(lambda x: x.strftime('%H:%M:%S'))\n",
        "  return any(':00' not in str_time for str_time in df['Time'])"
      ],
      "metadata": {
        "id": "7q1hwbOgRoSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_unique_dates(df):\n",
        "  return df['Date'].nunique()"
      ],
      "metadata": {
        "id": "ZaCkn4WQSHzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def date_datetime(df):\n",
        "  df['Date'] = pd.to_datetime(df['Date'])"
      ],
      "metadata": {
        "id": "xHERv6isSgCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unique_years(df):\n",
        "  return df['Date'].dt.year.unique()"
      ],
      "metadata": {
        "id": "2zxj-f3cSuTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_ordered_ascending(df):\n",
        "  return df['Date'].is_monotonic_increasing"
      ],
      "metadata": {
        "id": "MYRJmoxpTCzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def date_date_format(df):\n",
        "  df['Date'] = df['Date'].dt.date"
      ],
      "metadata": {
        "id": "qD6Q3iOVTuP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_date(df):\n",
        "  return df.sort_values(by='Date')"
      ],
      "metadata": {
        "id": "9vHKD2q3V__W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def year_month_day(df):\n",
        "  df['Year'] = df['Date'].dt.year\n",
        "  df['Month'] = df['Date'].dt.month\n",
        "  df['Day'] = df['Date'].dt.day\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "S0VLUQUFYV98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def average_measurements_per_day(df):\n",
        "  return df.groupby('Date').size().mean()"
      ],
      "metadata": {
        "id": "R8YZS-Y-z4AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def average_measurements_per_year(df):\n",
        "  return df.groupby(['Year', 'Date']).size().groupby('Year').mean()"
      ],
      "metadata": {
        "id": "B0ybqfZp5aO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def average_measurements_per_year_month(df):\n",
        "   return df.groupby(['Year', 'Month', 'Date']).size().groupby(['Year', 'Month']).mean()"
      ],
      "metadata": {
        "id": "DaShMKS45ado"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def measurements_per_year_month_boxplot(df):\n",
        "  daily_measurements_count = df.groupby(['Year', 'Month', 'Date']).size()\n",
        "\n",
        "  plot_data = daily_measurements_count.reset_index(name='Measurements')\n",
        "\n",
        "  for year in unique_years(df):\n",
        "      year_data = plot_data[plot_data['Year'] == year]\n",
        "\n",
        "      plt.figure(figsize=(8, 6))\n",
        "      sns.boxplot(x='Month', y='Measurements', data=year_data, whis=3, palette=\"Paired\")\n",
        "      plt.title(f'Número de medições diárias em {year}')\n",
        "      plt.xlabel('Month')\n",
        "      plt.ylabel('Número de medições')\n",
        "      plt.show()\n"
      ],
      "metadata": {
        "id": "bdvBM3YfJPUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unique_month_counts(df):\n",
        "  return df.drop_duplicates(subset=['Year', 'Month']).groupby('Year').size().reset_index(name='Número de meses')"
      ],
      "metadata": {
        "id": "Zhm9RuXOYoSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unique_days_counts(df):\n",
        "  return df.drop_duplicates(subset=['Year', 'Month','Day']).groupby('Year').size().reset_index(name='Número de dias')"
      ],
      "metadata": {
        "id": "sZcrb_MGYwr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expected_days_print(df):\n",
        "  for year, num_days in zip((unique_days_counts(df))['Year'], (unique_days_counts(df))['Número de dias']):\n",
        "\n",
        "    expected_days = 366 if pd.Timestamp(f'{year}-12-31').is_leap_year else 365\n",
        "    expected_days -= (12 - len(df[df['Year'] == year]['Month'].unique())) * 30\n",
        "\n",
        "    print(f\"Existem medições de {num_days} dias distintos em {year}. Esperava-se que existissem {expected_days}.\")"
      ],
      "metadata": {
        "id": "Yhr6iqfsZKAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def caudal_values_chart(df):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    for year in unique_years(df):\n",
        "        year_data = df[df['Year'] == year]\n",
        "        plt.plot(year_data['Date'], year_data['Caudal'], label=str(year))\n",
        "\n",
        "    plt.xlabel('Data')\n",
        "    plt.ylabel('Caudal')\n",
        "    plt.title('Valores de Caudal')\n",
        "    plt.legend(title='Ano')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "qQRzXTxeMTma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def caudal_values_chart_yearly(df):\n",
        "  for year in unique_years(df):\n",
        "    year_data = df[df['Year'] == year]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(year_data['Date'], year_data['Caudal'])\n",
        "    plt.xlabel('Data')\n",
        "    plt.ylabel('Caudal')\n",
        "    plt.title(f'Valores de Caudal em {year}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Qau679V1Zmiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_datetime(df):\n",
        "  df['Time'] = pd.to_datetime(df['Time'], errors='coerce')"
      ],
      "metadata": {
        "id": "KRB_5bOzdVrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def invalid_time_values(df):\n",
        "  return df[df['Time'].isna()]"
      ],
      "metadata": {
        "id": "CPNZ0NaqePob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_time(df):\n",
        "  df['Time'] = df['Time'].dt.time"
      ],
      "metadata": {
        "id": "zzWjI_uyfYcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_caudal(df):\n",
        "  df['Caudal'] = pd.to_numeric(df['Caudal'], errors='coerce')"
      ],
      "metadata": {
        "id": "JoQvMWJlfcQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fails(df):\n",
        "  return df[df['Caudal'].isna()]"
      ],
      "metadata": {
        "id": "QnPN-gt6fhE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def total_fails(df):\n",
        "  return len(fails(df))"
      ],
      "metadata": {
        "id": "8SPR7VNBgQaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_integer_counts(df):\n",
        "  non_integer_mask = df['Caudal'].isna()\n",
        "  return df[non_integer_mask].groupby('Year').size().reset_index(name='Número de Falhas')"
      ],
      "metadata": {
        "id": "-KGaR4pGghte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def days_with_no_data(df):\n",
        "  return df.groupby('Date').filter(lambda x: x['Caudal'].notna().any()).groupby('Date').filter(lambda x: x['Caudal'].isna().all())['Date'].unique()"
      ],
      "metadata": {
        "id": "tto-cYapxqg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entrys_per_year(df):\n",
        "  return df.groupby('Year')['Caudal'].count().reset_index(name='Número Total de medições')"
      ],
      "metadata": {
        "id": "g41skX_eygcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entries_without_errors_per_year(entrys_per_year_df, non_integer_counts_df):\n",
        "  entries_without_fails_per_year = entrys_per_year_df.copy()\n",
        "  entries_without_fails_per_year['Medições sem Falhas'] = entrys_per_year_df['Número Total de medições'] - non_integer_counts_df['Número de Falhas']\n",
        "  return entries_without_fails_per_year"
      ],
      "metadata": {
        "id": "N1ruB9_Gy9Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entries_without_errors_per_year_percent(df):\n",
        "  df['Medições sem falhas (%)'] = ((df['Medições sem Falhas'] / df['Número Total de medições']) * 100)\n",
        "\n",
        "  entries_without_errors_per_year_percent = df.copy()\n",
        "  entries_without_errors_per_year_percent.drop('Medições sem Falhas', axis=1, inplace=True)\n",
        "\n",
        "  return entries_without_errors_per_year_percent"
      ],
      "metadata": {
        "id": "fFqGagquz7fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entries_with_errors_per_year_percent(df):\n",
        "  entries_with_errors_per_year_percent = df.copy()\n",
        "\n",
        "  entries_with_errors_per_year_percent['Medições com falhas (%)'] = (\n",
        "    (100 - df['Medições sem falhas (%)'])\n",
        "  )\n",
        "\n",
        "  entries_with_errors_per_year_percent.drop('Medições sem falhas (%)', axis=1, inplace=True)\n",
        "\n",
        "  return entries_with_errors_per_year_percent"
      ],
      "metadata": {
        "id": "AkUqxF8I0yoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unique_years_no_error(df):\n",
        "  return (df_no_errors(df))['Year'].unique()"
      ],
      "metadata": {
        "id": "tiW-UcO497Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_no_errors(df):\n",
        "  return df[~df['Caudal'].isna()]"
      ],
      "metadata": {
        "id": "8BS5FJ4m-oC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_results(df, no_errors_df):\n",
        "  return no_errors_df.groupby(['Year', 'Month'], as_index=False).agg(\n",
        "    Average=('Caudal', 'mean'),\n",
        "  ).reset_index()"
      ],
      "metadata": {
        "id": "8FbBwvnS-PGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_results_yearly(df, no_errors_df):\n",
        "  return no_errors_df.groupby('Year', as_index=False).agg(\n",
        "    Average=('Caudal', 'mean'),\n",
        "  ).reset_index()"
      ],
      "metadata": {
        "id": "qXq-GWqu--fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def means_caudal_yearly(df):\n",
        "\n",
        "  no_errors_df = df_no_errors(df)\n",
        "\n",
        "  result = mean_results(df, no_errors_df)\n",
        "\n",
        "  result_yearly = mean_results_yearly(df, no_errors_df)\n",
        "\n",
        "  for year in unique_years_no_error(df):\n",
        "    year_data = result[result['Year'] == year]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(year_data['Month'] , year_data['Average'], label='Média', marker='o', linestyle='-')\n",
        "\n",
        "    plt.axhline(result_yearly.loc[result_yearly['Year'] == year, 'Average'].values[0], linestyle='dashed', color='blue',\n",
        "                label= f'Média anual : {result_yearly.loc[result_yearly[\"Year\"] == year, \"Average\"].values[0]:.2f}')\n",
        "\n",
        "    for i, avg in enumerate(year_data['Average']):\n",
        "      plt.text(year_data['Month'].iloc[i] , avg, f'{avg:.2f}', ha='center', va='bottom', color='blue')\n",
        "\n",
        "    plt.xlabel('Mês')\n",
        "    plt.ylabel('Caudal')\n",
        "    plt.title(f'Média das medições de Caudal do ano {year}')\n",
        "    plt.xticks(range(1, 13), [str(month) for month in range(1, 13)])\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "TPis9m4V1dvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def means_caudal(df):\n",
        "\n",
        "  no_errors_df = df_no_errors(df)\n",
        "\n",
        "  result = mean_results(df, no_errors_df)\n",
        "\n",
        "  result_yearly = mean_results_yearly(df, no_errors_df)\n",
        "\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  for year in unique_years_no_error(df):\n",
        "    year_data = result[result['Year'] == year]\n",
        "    plt.plot(year_data['Month'], year_data['Average'], label=f'Ano {year}')\n",
        "\n",
        "  overall_monthly_average = result.groupby('Month')['Average'].mean()\n",
        "\n",
        "  plt.plot(overall_monthly_average.index, overall_monthly_average.values, label='Média Geral', linestyle='--', color='black')\n",
        "\n",
        "  plt.xlabel('Mês')\n",
        "  plt.ylabel('Caudal')\n",
        "  plt.title('Médias de medições de Caudal')\n",
        "  plt.xticks(range(1, 13), [str(month) for month in range(1, 13)])\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "e9F8HXpm2F2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def std_monthly(df):\n",
        "  return df.groupby(['Year', 'Month'], as_index=False).agg(\n",
        "    Desvio_Padrao=('Caudal', 'std')\n",
        ").reset_index()"
      ],
      "metadata": {
        "id": "69qSjDZiCnSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def std_yearly(df):\n",
        "  return df.groupby('Year', as_index=False).agg(\n",
        "    Desvio_Padrao=('Caudal', 'std')\n",
        ").reset_index()\n"
      ],
      "metadata": {
        "id": "7vIcrOOzCvJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def caudal_boxplots(df):\n",
        "  for year in unique_years_no_error(df):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    year_data = df[df['Year'] == year]\n",
        "\n",
        "    ax = sns.boxplot(x='Month', y='Caudal', data=year_data, whis=3, palette=\"Set3\")\n",
        "\n",
        "    plt.title(f'Boxplot das medições de Caudal em {year}')\n",
        "    plt.xlabel('Mês')\n",
        "    plt.ylabel('Medição do Caudal')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "5tcFtVtpWq8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def caudal_statistics(df_no_errors):\n",
        "  dfs = []\n",
        "\n",
        "  for year in df_no_errors['Year'].unique():\n",
        "    for month in df_no_errors['Month'].unique():\n",
        "        subset_data = df_no_errors[(df_no_errors['Year'] == year) & (df_no_errors['Month'] == month)]\n",
        "\n",
        "        if not subset_data.empty:\n",
        "            min_value = subset_data['Caudal'].min()\n",
        "            q1_value = np.percentile(subset_data['Caudal'], 25)\n",
        "            median_value = np.median(subset_data['Caudal'])\n",
        "            q3_value = np.percentile(subset_data['Caudal'], 75)\n",
        "            max_value = subset_data['Caudal'].max()\n",
        "\n",
        "            dfs.append(pd.DataFrame({\n",
        "                'Year': [year],\n",
        "                'Month': [month],\n",
        "                'Min_Value': [min_value],\n",
        "                'Q1_Value': [q1_value],\n",
        "                'Median': [median_value],\n",
        "                'Q3_Value': [q3_value],\n",
        "                'Max_Value': [max_value]\n",
        "            }))\n",
        "\n",
        "  summary_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "  summary_df_sorted = summary_df.sort_values(by=['Year', 'Month'])\n",
        "  return summary_df_sorted"
      ],
      "metadata": {
        "id": "gYSx6cOrXAAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resultados(df):\n",
        "\n",
        "  print(f\"Existem {num_rows(df)} medições de Caudal. \\n\")\n",
        "\n",
        "  print(f\"A DataFrame tem {num_columns(df)} colunas \\n\")\n",
        "\n",
        "  date_and_time(df)\n",
        "\n",
        "  if (duplicates(df)).any():\n",
        "    print(\"Linhas duplicadas:\")\n",
        "    print(df[duplicates])\n",
        "    df = df.drop_duplicates(subset=['Data'])\n",
        "  else:\n",
        "    print(\"Não existem duplicados.\\n\")\n",
        "\n",
        "  print(\"Média de tempo entre medições:\", mean_time_difference(df), \"\\n\")\n",
        "\n",
        "  print(\"Média de tempo entre medições por ano:\")\n",
        "  print(mean_time_difference_per_year(df))\n",
        "\n",
        "  print(\"\\nMédia de tempo entre medições por ano e mês:\")\n",
        "  print(mean_time_difference_per_month(df))\n",
        "\n",
        "\n",
        "  df.drop('Data', axis=1, inplace=True)\n",
        "\n",
        "  df = format(df)\n",
        "\n",
        "  if has_seconds(df):\n",
        "    subset = df[df['Time'].apply(lambda x: ':00' not in x)]\n",
        "    print(\"\\n Os dados com valor nos segundos:\")\n",
        "    print(subset)\n",
        "  else:\n",
        "    print(\"\\n O valor dos segundos está sempre a 00.\\n\")\n",
        "\n",
        "\n",
        "  print(f\"Existem medições de {num_unique_dates(df)} dias distintos.\\n\")\n",
        "\n",
        "  date_datetime(df)\n",
        "\n",
        "  print(\"Temos dados dos seguintes anos:\")\n",
        "  print(unique_years(df))\n",
        "\n",
        "  if is_ordered_ascending(df):\n",
        "    print(\"\\n Os dados estão organizados de forma cronológica.\\n\")\n",
        "  else:\n",
        "    print(\"\\n Os dados não estão organizados de forma cronológica.\\n\")\n",
        "    df = sort_date(df)\n",
        "\n",
        "  date_date_format(df)\n",
        "  print(f\"A primeira medição foi feita em: {df['Date'][0]}\\n\")\n",
        "  print(f\"A ultima medição foi feita em: {df['Date'][len(df)-1]}\\n\")\n",
        "\n",
        "  date_datetime(df)\n",
        "  df = year_month_day(df)\n",
        "\n",
        "  print(f\"Valor médio de medições diárias: {average_measurements_per_day(df)} \\n\")\n",
        "\n",
        "  print(\"Valor médio de medições diárias por ano:\")\n",
        "  print(average_measurements_per_year(df))\n",
        "\n",
        "  print(\"\\nValor médio de medições diárias por ano e mês:\")\n",
        "  print(average_measurements_per_year_month(df))\n",
        "\n",
        "  measurements_per_year_month_boxplot(df)\n",
        "\n",
        "  print(\"\\n Quantos meses tiveram medições naquele ano:\")\n",
        "  print(unique_month_counts(df))\n",
        "\n",
        "  print(\"\\n Quantos dias tiveram medições naquele ano:\")\n",
        "  print(unique_days_counts(df))\n",
        "  print('\\n')\n",
        "\n",
        "  expected_days_print(df)\n",
        "\n",
        "  caudal_values_chart(df)\n",
        "  caudal_values_chart_yearly(df)\n",
        "\n",
        "  time_datetime(df)\n",
        "\n",
        "  if not invalid_time_values(df).empty:\n",
        "    print(\"\\n Existem falhas no tempo das seguintes leituras:\")\n",
        "    print(invalid_time_values(df))\n",
        "  else:\n",
        "    print(\"\\n Não existem falhas nos tempos\")\n",
        "\n",
        "  time_time(df)\n",
        "\n",
        "  if not fails(df).empty:\n",
        "    print(\"\\n Existem as seguintes falhas nos dados:\")\n",
        "    print(format(fails(df)))\n",
        "  else:\n",
        "    print(\"\\n Não existem falhas nos dados.\")\n",
        "\n",
        "  print(f\"\\n Existem {total_fails(df)} falhas de leituras \\n\")\n",
        "\n",
        "  correct_caudal(df)\n",
        "\n",
        "  fails_count = non_integer_counts(df)\n",
        "  print(\"Número de falhas por ano:\")\n",
        "  print(fails_count)\n",
        "\n",
        "  days_without_data = days_with_no_data(df)\n",
        "  if len(days_without_data) > 0:\n",
        "    print(\"\\n Existem dias inteiros sem valores.\")\n",
        "    print(\"Dias sem valores:\", days_without_data)\n",
        "  else:\n",
        "    print(\"\\n Todos os dias tem pelo menos uma medição sem falhas.\")\n",
        "\n",
        "  entrys_year = entrys_per_year(df)\n",
        "  print('\\n Número de medições por ano:')\n",
        "  print(entrys_year)\n",
        "\n",
        "  entries_without_fails_per_year = entries_without_errors_per_year(entrys_year, fails_count)\n",
        "  print(\"\\n Número de medições sem falhas:\")\n",
        "  print(entries_without_fails_per_year)\n",
        "\n",
        "  entries_without_fails_per_year_percent = entries_without_errors_per_year_percent(entries_without_fails_per_year)\n",
        "  print(\"\\n Percentagem de medições sem falhas:\")\n",
        "  print(entries_without_fails_per_year_percent)\n",
        "\n",
        "  print(\"\\n Percentagem de medições com falhas:\")\n",
        "  print(entries_with_errors_per_year_percent(entries_without_fails_per_year_percent))\n",
        "\n",
        "  print('\\n')\n",
        "  means_caudal_yearly(df)\n",
        "  means_caudal(df)\n",
        "\n",
        "  print(\"\\n\", (std_monthly(df_no_errors(df)))[['Year', 'Month', 'Desvio_Padrao']])\n",
        "  print(\"\\n\", (std_yearly(df_no_errors(df)))[['Year', 'Desvio_Padrao']])\n",
        "\n",
        "  print('\\n')\n",
        "  caudal_boxplots(df)\n",
        "  print('\\n')\n",
        "  print(caudal_statistics(df_no_errors(df)))"
      ],
      "metadata": {
        "id": "_pxQmwGD2Wz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unico Output"
      ],
      "metadata": {
        "id": "YHGpeZTxUPbr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alcogulhe"
      ],
      "metadata": {
        "id": "XouInp6WYi7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alcogulhe = pd.read_excel(\"/content/alcogulhe.xlsx\")\n",
        "\n",
        "resultados(alcogulhe)"
      ],
      "metadata": {
        "id": "aH9Gv_ztUREz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arnal"
      ],
      "metadata": {
        "id": "8ZHCL0sXYnQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arnal = pd.read_excel(\"/content/arnal.xlsx\")\n",
        "\n",
        "resultados(arnal)"
      ],
      "metadata": {
        "id": "yJfziQADZAQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cerca"
      ],
      "metadata": {
        "id": "mHgGS6rOYqvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cerca = pd.read_excel(\"/content/cerca.xlsx\")\n",
        "\n",
        "resultados(cerca)"
      ],
      "metadata": {
        "id": "5niUnST9ZA3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Maceirinha"
      ],
      "metadata": {
        "id": "fWt5wpaOYvOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maceirinha = pd.read_excel(\"/content/maceirinha.xlsx\")\n",
        "\n",
        "resultados(maceirinha)"
      ],
      "metadata": {
        "id": "lQI0pZJGZCQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Porto Carro"
      ],
      "metadata": {
        "id": "Vjy6hfiyYyyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "porto_carro = pd.read_excel(\"/content/porto_carro.xlsx\")\n",
        "\n",
        "resultados(porto_carro)"
      ],
      "metadata": {
        "id": "cJXqVEWFZC76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalização"
      ],
      "metadata": {
        "id": "qZUC9_yjzHjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/.xlsx\")"
      ],
      "metadata": {
        "id": "URBs8J8_0xR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Funcões"
      ],
      "metadata": {
        "id": "P7pmTjO10uwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(resampled_df, time):\n",
        "    for col in resampled_df.columns:\n",
        "\n",
        "        missing_mask = resampled_df[col].isnull()\n",
        "\n",
        "        for idx, value in resampled_df[col][missing_mask].items():\n",
        "\n",
        "            before_idx = None\n",
        "            for i in reversed(range(resampled_df.index.get_loc(idx))):\n",
        "                if not pd.isnull(resampled_df.at[resampled_df.index[i], col]):\n",
        "                    before_idx = resampled_df.index[i]\n",
        "                    break\n",
        "            after_idx = None\n",
        "            for i in range(resampled_df.index.get_loc(idx), len(resampled_df.index)):\n",
        "                if not pd.isnull(resampled_df.at[resampled_df.index[i], col]):\n",
        "                    after_idx = resampled_df.index[i]\n",
        "                    break\n",
        "\n",
        "            if before_idx is not None and after_idx is not None and (after_idx - before_idx).total_seconds() <= pd.Timedelta(minutes=time).total_seconds():\n",
        "                resampled_df.at[idx, col] = resampled_df[col][before_idx] + \\\n",
        "                                            ((resampled_df[col][after_idx] - resampled_df[col][before_idx]) /\n",
        "                                            (after_idx - before_idx).total_seconds()) * \\\n",
        "                                            (idx - before_idx).total_seconds()"
      ],
      "metadata": {
        "id": "oRi4Ur9B0trE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def years(df):\n",
        "  return df.index.year.unique()\n",
        "\n",
        "def normalizedPlot(df, time):\n",
        "\n",
        "  plt.figure(figsize=(10, 6))\n",
        "\n",
        "\n",
        "  for year in years(df):\n",
        "\n",
        "      year_data = df[df.index.year == year]\n",
        "\n",
        "      plt.plot(year_data.index, year_data['Caudal'], label=str(year))\n",
        "\n",
        "  plt.xlabel('Data')\n",
        "  plt.ylabel('Caudal')\n",
        "  plt.title(f'Valores normalizados com intervalo máximo de {time} minutos')\n",
        "  plt.legend(title='Ano')\n",
        "\n",
        "  plt.ylim(-5, 90)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "E1YomqTU04G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mean_area(df):\n",
        "    mean_areas = {}\n",
        "    for date, data in df.groupby(df.index.date):\n",
        "        times = data.index.time\n",
        "        values = data['Caudal']\n",
        "        areas = []\n",
        "        for i in range(len(values) - 1):\n",
        "            if not pd.isnull(values[i]) and not pd.isnull(values[i + 1]):\n",
        "                x = np.array([times[i].hour * 3600 + times[i].minute * 60 + times[i].second,\n",
        "                              times[i + 1].hour * 3600 + times[i + 1].minute * 60 + times[i + 1].second])\n",
        "                y = np.array([values[i], values[i + 1]])\n",
        "                areas.append(np.trapz(y, x))\n",
        "        if areas:\n",
        "            mean_areas[date] = np.mean(areas)\n",
        "    return mean_areas"
      ],
      "metadata": {
        "id": "bDALLNVb0-ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def diference(df, column1, column2):\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.plot(df['Date'], df[f'{column1}'] - df[f'{column2}'], marker='o')\n",
        "  plt.xlabel('Date')\n",
        "  plt.ylabel('Difference in Area')\n",
        "  plt.title('Difference in Daily Mean Area between Old and New DataFrames')\n",
        "  plt.xticks(rotation=45)\n",
        "  plt.grid(True)\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "eJOwnQ9gY9Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def comparison(df, column1, column2):\n",
        "  df.plot(kind='scatter', x=column1, y=column2, s=32, alpha=.8)\n",
        "  plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "metadata": {
        "id": "cf1h4QNtLlL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers_iqr(df, column):\n",
        "    df['Year'] = df['Data'].dt.year\n",
        "    df['Month'] = df['Data'].dt.month\n",
        "    grouped = df.groupby(['Year', 'Month'])\n",
        "\n",
        "    df_filtered = pd.DataFrame()\n",
        "    outliers_above = pd.DataFrame()\n",
        "    outliers_below = pd.DataFrame()\n",
        "\n",
        "    for (year, month), group in grouped:\n",
        "        Q1 = group[column].quantile(0.25)\n",
        "        Q3 = group[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "\n",
        "        lower_bound = Q1 - 3 * IQR\n",
        "        upper_bound = Q3 + 3 * IQR\n",
        "\n",
        "        group_filtered = group[(group[column] >= lower_bound) & (group[column] <= upper_bound)]\n",
        "        outliers_above_group = group[group[column] > upper_bound]\n",
        "        outliers_below_group = group[group[column] < lower_bound]\n",
        "\n",
        "        df_filtered = pd.concat([df_filtered, group_filtered])\n",
        "        outliers_above = pd.concat([outliers_above, outliers_above_group])\n",
        "        outliers_below = pd.concat([outliers_below, outliers_below_group])\n",
        "\n",
        "    return df_filtered, outliers_above, outliers_below\n"
      ],
      "metadata": {
        "id": "0zxen2wW1SMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def boxplot_outliers(df):\n",
        "  df['Data'] = pd.to_datetime(df['Data'])\n",
        "\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.boxplot(df['Caudal'], whis=100)\n",
        "  plt.title('Diagrama de Caixas dos Outliers')\n",
        "  plt.ylabel('Caudal')\n",
        "  plt.xticks([1], ['Caudal'])\n",
        "  plt.grid(True)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "RJMhZERd1UxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def statistics(df_no_errors):\n",
        "    dfs = []\n",
        "\n",
        "    df_no_errors['Year'] = df_no_errors['Data'].dt.year\n",
        "    df_no_errors['Month'] = df_no_errors['Data'].dt.month\n",
        "\n",
        "    for year in df_no_errors['Year'].unique():\n",
        "        for month in df_no_errors['Month'].unique():\n",
        "            subset_data = df_no_errors[(df_no_errors['Year'] == year) & (df_no_errors['Month'] == month)]\n",
        "\n",
        "            if not subset_data.empty:\n",
        "                min_value = subset_data['Caudal'].min()\n",
        "                max_value = subset_data['Caudal'].max()\n",
        "                count = len(subset_data)\n",
        "\n",
        "                dfs.append(pd.DataFrame({\n",
        "                    'Year': [year],\n",
        "                    'Month': [month],\n",
        "                    'Min_Value': [min_value],\n",
        "                    'Max_Value': [max_value],\n",
        "                    'Count': [count]\n",
        "                }))\n",
        "\n",
        "    summary_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    summary_df_sorted = summary_df.sort_values(by=['Year', 'Month'])\n",
        "    return summary_df_sorted"
      ],
      "metadata": {
        "id": "cnNfBL2W1YMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def missings_study(df):\n",
        "  df['TimeDiff'] = df['Data'].diff()\n",
        "\n",
        "  group_start = df.iloc[0]['Data']\n",
        "  group_count = 1\n",
        "\n",
        "  result_dates = []\n",
        "  result_consecutive_points = []\n",
        "  result_time = []\n",
        "\n",
        "  for i in range(1, len(df)):\n",
        "      if df.iloc[i]['Data'] - df.iloc[i - 1]['Data'] > pd.Timedelta(minutes=15):\n",
        "          result_dates.append(group_start)\n",
        "          result_consecutive_points.append(group_count)\n",
        "          duration_minutes = group_count * 15\n",
        "          days = duration_minutes // (24 * 60)\n",
        "          remaining_minutes = duration_minutes % (24 * 60)\n",
        "          hours = remaining_minutes // 60\n",
        "          minutes = remaining_minutes % 60\n",
        "          time_str = f\"{days} days {hours:02d}:{minutes:02d}:00\"\n",
        "          result_time.append(time_str)\n",
        "          group_start = df.iloc[i]['Data']\n",
        "          group_count = 1\n",
        "      else:\n",
        "          group_count += 1\n",
        "\n",
        "  result_dates.append(group_start)\n",
        "  result_consecutive_points.append(group_count)\n",
        "  duration_minutes = (group_count - 1) * 15\n",
        "  days = duration_minutes // (24 * 60)\n",
        "  remaining_minutes = duration_minutes % (24 * 60)\n",
        "  hours = remaining_minutes // 60\n",
        "  minutes = remaining_minutes % 60\n",
        "  time_str = f\"{days} days {hours:02d}:{minutes:02d}:00\"\n",
        "  result_time.append(time_str)\n",
        "\n",
        "  return pd.DataFrame({'Data': result_dates, 'Consecutive_Points': result_consecutive_points, 'Time': result_time})"
      ],
      "metadata": {
        "id": "xDu4PeCp1l4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_time(value):\n",
        "    minutes = value * 15\n",
        "    hours = minutes // 60\n",
        "    minutes = minutes % 60\n",
        "    days = hours // 24\n",
        "    hours = hours % 24\n",
        "    seconds = 0\n",
        "    return '{} days {:02d}:{:02d}:{:02d}'.format(int(days), int(hours), int(minutes), int(seconds))"
      ],
      "metadata": {
        "id": "IbK8SZAA7LwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_time_less_than_1day(value):\n",
        "    minutes = value * 15\n",
        "    hours = minutes // 60\n",
        "    minutes = minutes % 60\n",
        "    seconds = 0\n",
        "    return '{:02d}:{:02d}:{:02d}'.format(int(hours), int(minutes), int(seconds))"
      ],
      "metadata": {
        "id": "eEM6CrS48_dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Com outliers"
      ],
      "metadata": {
        "id": "v11C5Uwr0i8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "copy_df = df.copy()"
      ],
      "metadata": {
        "id": "ked4HN3hWtCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_df['Data'] = pd.to_datetime(df['Data'])"
      ],
      "metadata": {
        "id": "hF07N2b9C7gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_df.set_index('Data', inplace=True)"
      ],
      "metadata": {
        "id": "H9cBJP1eJr9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resampled_df = copy_df.resample('15T').asfreq()"
      ],
      "metadata": {
        "id": "G3IUup2QzNzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max30min_df = resampled_df.copy()\n",
        "max15min_df = resampled_df.copy()\n",
        "max60min_df = resampled_df.copy()"
      ],
      "metadata": {
        "id": "jtLDuE5YI5bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize(max30min_df, 30)\n",
        "normalize(max15min_df, 15)\n",
        "normalize(max60min_df, 60)"
      ],
      "metadata": {
        "id": "qRYwLrxaLi5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizedPlot(max30min_df, 30)"
      ],
      "metadata": {
        "id": "8N1ldjtBP7bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizedPlot(max15min_df, 15)"
      ],
      "metadata": {
        "id": "vshFDx1iQA1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizedPlot(max60min_df, 60)"
      ],
      "metadata": {
        "id": "0SFNfE32QDaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_areas = calculate_mean_area(copy_df)"
      ],
      "metadata": {
        "id": "70MDsOD_it2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_areas = calculate_mean_area(copy_df)\n",
        "max30min_areas = calculate_mean_area(max30min_df)\n",
        "max15min_areas = calculate_mean_area(max15min_df)\n",
        "max60min_areas = calculate_mean_area(max60min_df)\n",
        "\n",
        "original_areas_df = pd.DataFrame(list(original_areas.items()), columns=['Date', 'Original_Area'])\n",
        "max30min_areas_df = pd.DataFrame(list(max30min_areas.items()), columns=['Date', 'New_Area'])\n",
        "max15min_areas_df = pd.DataFrame(list(max15min_areas.items()), columns=['Date', 'New_Area'])\n",
        "max60min_areas_df = pd.DataFrame(list(max60min_areas.items()), columns=['Date', 'New_Area'])\n",
        "\n",
        "comparison_max30min_df = original_areas_df.merge(max30min_areas_df, on='Date', how='outer')\n",
        "comparison_max15min_df = original_areas_df.merge(max15min_areas_df, on='Date', how='outer')\n",
        "comparison_max60min_df = original_areas_df.merge(max60min_areas_df, on='Date', how='outer')"
      ],
      "metadata": {
        "id": "CcNOAcd1Wozi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diference(comparison_max30min_df, 'Original_Area', 'New_Area')"
      ],
      "metadata": {
        "id": "nZN1zGfrjljr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diference(comparison_max15min_df, 'Original_Area', 'New_Area')"
      ],
      "metadata": {
        "id": "dgw86r99lYd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diference(comparison_max60min_df, 'Original_Area', 'New_Area')"
      ],
      "metadata": {
        "id": "wj4uco-flZU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max30min_vs_max15min= comparison_max30min_df.merge(comparison_max15min_df, on='Date', how='outer')\n",
        "max30min_vs_max60min = comparison_max30min_df.merge(comparison_max60min_df, on='Date', how='outer')\n",
        "max15min_vs_max60min = comparison_max15min_df.merge(comparison_max60min_df, on='Date', how='outer')"
      ],
      "metadata": {
        "id": "3g6HYxNVEchH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison(max30min_vs_max15min, 'New_Area_x', 'New_Area_y')"
      ],
      "metadata": {
        "id": "bw8MfQE_E0vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison(max30min_vs_max60min, 'New_Area_x', 'New_Area_y')"
      ],
      "metadata": {
        "id": "1OAWAq7yE3MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison(max15min_vs_max60min, 'New_Area_x', 'New_Area_y')"
      ],
      "metadata": {
        "id": "kvKNG9YPE3n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sem Outliers"
      ],
      "metadata": {
        "id": "pXG-D9nm_pTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_outliers = df.copy()\n",
        "no_outliers, outliers_above, outliers_below = remove_outliers_iqr(no_outliers, 'Caudal')"
      ],
      "metadata": {
        "id": "fB5FgWyC_zwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_outlier_above = outliers_above\n",
        "original_outlier_below = outliers_below"
      ],
      "metadata": {
        "id": "WP3Zn1sqBm4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missings_df = df[df['Caudal'].isna()].copy()\n",
        "print(statistics(missings_df).drop(['Min_Value', 'Max_Value'], axis=1))\n",
        "\n",
        "print(f\"\\nExistem {len(missings_df)} valores omissos o que corresponde a  {(len(missings_df)*100)/(len(no_outliers) + len(missings_df))}% da amostra\")"
      ],
      "metadata": {
        "id": "PDOwSxE25k9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(outliers_above)"
      ],
      "metadata": {
        "id": "eYOEyaY70bP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(outliers_below)"
      ],
      "metadata": {
        "id": "vo5y_GP50hJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (len(outliers_above) > 0):\n",
        "  boxplot_outliers(outliers_above)"
      ],
      "metadata": {
        "id": "Zftn5oGjSZeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (len(outliers_above) > 0):\n",
        "  print(statistics(outliers_above))\n",
        "\n",
        "print(f\"\\nforam retirados {len(outliers_above)} valores, o que corresponde a {(len(outliers_above)*100)/(len(no_outliers) + len(df[df['Caudal'].isna()]))}% da amostra\")"
      ],
      "metadata": {
        "id": "dOfdS5MhCPvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outliers_above"
      ],
      "metadata": {
        "id": "tgixZK49pNl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (len(outliers_below) > 0):\n",
        "  boxplot_outliers(outliers_below)"
      ],
      "metadata": {
        "id": "iooVWCsnGZzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (len(outliers_below) > 0):\n",
        "  print(statistics(outliers_below))\n",
        "\n",
        "print(f\"\\nforam retirados {len(outliers_below)} valores, o que corresponde a {(len(outliers_below)*100)/(len(no_outliers) + len(df[df['Caudal'].isna()]))}% da amostra\")"
      ],
      "metadata": {
        "id": "AR1CccwzGakC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_outliers['Data'] = pd.to_datetime(df['Data'])"
      ],
      "metadata": {
        "id": "xqzHcOPtARNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_outliers.set_index('Data', inplace=True)"
      ],
      "metadata": {
        "id": "twfbXvseAn-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resampled_df = no_outliers.resample('15T').asfreq()\n",
        "\n",
        "closest_before = np.empty(len(resampled_df))\n",
        "closest_after = np.empty(len(resampled_df))\n",
        "data_before = [pd.NaT] * len(resampled_df)\n",
        "data_after = [pd.NaT] * len(resampled_df)\n",
        "\n",
        "no_outliers_idx = no_outliers.index.values\n",
        "no_outliers_caudal = no_outliers['Caudal'].values\n",
        "\n",
        "total_rows = len(resampled_df)\n",
        "for idx, (i, row) in enumerate(resampled_df.iterrows()):\n",
        "    if pd.isnull(row['Caudal']):\n",
        "        idx_before = np.where(no_outliers_idx < i)[0]\n",
        "        if len(idx_before) > 0:\n",
        "            closest_before[idx] = no_outliers_caudal[idx_before[-1]]\n",
        "            data_before[idx] = no_outliers_idx[idx_before[-1]]\n",
        "        else:\n",
        "            closest_before[idx] = np.nan\n",
        "\n",
        "        idx_after = np.where(no_outliers_idx > i)[0]\n",
        "        if len(idx_after) > 0:\n",
        "            closest_after[idx] = no_outliers_caudal[idx_after[0]]\n",
        "            data_after[idx] = no_outliers_idx[idx_after[0]]\n",
        "        else:\n",
        "            closest_after[idx] = np.nan\n",
        "    else:\n",
        "        closest_before[idx] = row['Caudal']\n",
        "        closest_after[idx] = row['Caudal']\n",
        "        data_before[idx] = i\n",
        "        data_after[idx] = i\n",
        "\n",
        "    if idx % (total_rows // 20) == 0:\n",
        "        print(f\"{int((idx / total_rows) * 100)}% done\")\n",
        "\n",
        "closest_df = pd.DataFrame({\n",
        "    'Data_before': data_before,\n",
        "    'Closest_before': closest_before,\n",
        "    'Data_after': data_after,\n",
        "    'Closest_after': closest_after\n",
        "}, index=resampled_df.index)\n"
      ],
      "metadata": {
        "id": "PNP23s4Yj1vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "closest_df"
      ],
      "metadata": {
        "id": "aPboYPeom4tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "closest_df['time_gap'] = (closest_df['Data_after'] - closest_df['Data_before']).dt.total_seconds() <= 30 * 60"
      ],
      "metadata": {
        "id": "quMG4dYGbnYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "closest_df"
      ],
      "metadata": {
        "id": "I7S9UO7OYdd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_caudal(row):\n",
        "    if row['time_gap']:\n",
        "        x = row.name\n",
        "        x1 = row['Data_before']\n",
        "        x2 = row['Data_after']\n",
        "        y1 = row['Closest_before']\n",
        "        y2 = row['Closest_after']\n",
        "        time_diff = (x2 - x1).total_seconds()\n",
        "        if time_diff == 0:\n",
        "            return y1\n",
        "        else:\n",
        "            caudal = y1 + ((x - x1).total_seconds() * (y2 - y1) / time_diff)\n",
        "            return caudal\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "closest_df['Caudal'] = closest_df.apply(calculate_caudal, axis=1)"
      ],
      "metadata": {
        "id": "-eqSOp4HaIF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resampled_df['Caudal'] = closest_df['Caudal']"
      ],
      "metadata": {
        "id": "6uV-AIshqs3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resampled_df"
      ],
      "metadata": {
        "id": "udQltYwGbl_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missings_normalized = resampled_df[resampled_df['Caudal'].isna()].copy()\n",
        "missings_normalized.reset_index(inplace=True)\n",
        "print(statistics(missings_normalized).drop(['Min_Value', 'Max_Value'], axis=1))\n",
        "\n",
        "print(f\"\\nExistem {len(missings_normalized)} valores omissos o que corresponde a  {(len(missings_normalized)*100)/len(resampled_df)}% da amostra\")"
      ],
      "metadata": {
        "id": "Gu-kL1WE7VMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max30min_df = resampled_df.copy()\n",
        "max15min_df = resampled_df.copy()\n",
        "max60min_df = resampled_df.copy()"
      ],
      "metadata": {
        "id": "rpjbWgfWA5CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizedPlot(max30min_df, 30)"
      ],
      "metadata": {
        "id": "DO4QYYR1BPhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizedPlot(max15min_df, 15)"
      ],
      "metadata": {
        "id": "E0KjqNjpBP9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizedPlot(max60min_df, 60)"
      ],
      "metadata": {
        "id": "R-H4JxaSBQRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_caudal_df_30 = max30min_df[max30min_df['Caudal'].isna()].copy()\n",
        "nan_caudal_df_15 = max15min_df[max15min_df['Caudal'].isna()].copy()\n",
        "nan_caudal_df_60 = max60min_df[max60min_df['Caudal'].isna()].copy()"
      ],
      "metadata": {
        "id": "_McJPexuWNoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_caudal_df_30 = max30min_df[max30min_df['Caudal'].notna()].copy()\n",
        "#NOT BEING USED"
      ],
      "metadata": {
        "id": "LlIvaWHfGN85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_caudal_df_30.reset_index(inplace=True)\n",
        "nan_caudal_df_15.reset_index(inplace=True)\n",
        "nan_caudal_df_60.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "UwiVyHaXaDwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missings_gap30_df = missings_study(nan_caudal_df_30)"
      ],
      "metadata": {
        "id": "mct0eR50pZYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missings_gap15_df = missings_study(nan_caudal_df_15)"
      ],
      "metadata": {
        "id": "HrV_-1VBgpVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missings_gap60_df = missings_study(nan_caudal_df_60)"
      ],
      "metadata": {
        "id": "YnCr0MGDgpoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "96 = 1 dia <br>\n",
        "192 = 2 dias"
      ],
      "metadata": {
        "id": "VYGOoOeemNgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yticks_values = [0, 50, 100, 150]\n",
        "yticks_labels = [convert_to_time(y) for y in yticks_values]\n",
        "\n",
        "sns.boxplot(data=missings_gap30_df, whis=100)\n",
        "plt.yticks(yticks_values, yticks_labels)\n",
        "plt.title(\"Estudo de Falhas pós normalização\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ds4TY9zijyBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_index = missings_gap30_df['Consecutive_Points'].idxmax()\n",
        "row_with_max_points = missings_gap30_df.loc[max_index]\n",
        "print(row_with_max_points)"
      ],
      "metadata": {
        "id": "zEweVBJa4an6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missings_gap15_df"
      ],
      "metadata": {
        "id": "Erb5snoekmd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yticks_values = [0, 50, 100, 150, 200, 250]\n",
        "yticks_labels = [convert_to_time(y) for y in yticks_values]\n",
        "\n",
        "sns.boxplot(data=missings_gap15_df, whis=100)\n",
        "plt.yticks(yticks_values, yticks_labels)\n",
        "plt.title(\"Estudo de Falhas pós normalização com intervalos máximos de 15 min\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "axv4TGiLkv8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_index = missings_gap15_df['Consecutive_Points'].idxmax()\n",
        "row_with_max_points = missings_gap15_df.loc[max_index]\n",
        "print(row_with_max_points)"
      ],
      "metadata": {
        "id": "1_rjCj3l4Pyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missings_gap60_df"
      ],
      "metadata": {
        "id": "NkDAyyeulQK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yticks_values = [0, 50, 100, 150, 200, 250]\n",
        "yticks_labels = [convert_to_time(y) for y in yticks_values]\n",
        "\n",
        "sns.boxplot(data=missings_gap60_df, whis=100)\n",
        "plt.yticks(yticks_values, yticks_labels)\n",
        "plt.title(\"Estudo de Falhas pós normalização com intervalos máximos de 60 min\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sG-k3Jklld3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_index = missings_gap60_df['Consecutive_Points'].idxmax()\n",
        "row_with_max_points = missings_gap60_df.loc[max_index]\n",
        "print(row_with_max_points)"
      ],
      "metadata": {
        "id": "hpAUg8F-4h1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "above_96_30gap = missings_gap30_df[missings_gap30_df['Consecutive_Points'] > 96]\n",
        "count_above_96_30gap = above_96_30gap.shape[0]\n",
        "\n",
        "print(\"Número de falhas com duração maior que 1 dia:\", count_above_96_30gap)\n",
        "print(f\"Isto corresponde a {(count_above_96_30gap*100)/len(missings_gap30_df):.2f}% das falhas\")"
      ],
      "metadata": {
        "id": "Uwizq_U_mkyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "above_96_30gap"
      ],
      "metadata": {
        "id": "p1Y_Erh1n6d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "above_192_30gap = missings_gap30_df[missings_gap30_df['Consecutive_Points'] > 192]\n",
        "count_above_192_30gap = above_192_30gap.shape[0]\n",
        "\n",
        "print(\"Número de falhas com duração maior que 2 dias:\", count_above_192_30gap)\n",
        "print(f\"Isto corresponde a {(count_above_192_30gap*100)/len(missings_gap30_df):.2f}% das falhas\")"
      ],
      "metadata": {
        "id": "im7PpiBhnE-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "above_192_30gap"
      ],
      "metadata": {
        "id": "oclsSv9Oovmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "above_96_15gap = missings_gap15_df[missings_gap15_df['Consecutive_Points'] > 96]\n",
        "count_above_96_15gap = above_96_15gap.shape[0]\n",
        "\n",
        "print(\"Número de falhas com duração maior que 1 dia:\", count_above_96_15gap)\n",
        "print(f\"Isto corresponde a {(count_above_96_15gap*100)/len(missings_gap15_df):.2f}% das falhas\")"
      ],
      "metadata": {
        "id": "B0GLBifUnenC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "above_96_15gap"
      ],
      "metadata": {
        "id": "798m3OpJo6YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "above_192_15gap = missings_gap15_df[missings_gap15_df['Consecutive_Points'] > 192]\n",
        "count_above_192_15gap = above_192_15gap.shape[0]\n",
        "\n",
        "print(\"Número de falhas com duração maior que 2 dias:\", count_above_192_15gap)\n",
        "print(f\"Isto corresponde a {(count_above_192_15gap*100)/len(missings_gap15_df):.2f}% das falhas\")"
      ],
      "metadata": {
        "id": "hzGlzwLBnenP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "above_192_15gap"
      ],
      "metadata": {
        "id": "JgQpu1Lmo_JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "above_96_60gap = missings_gap60_df[missings_gap60_df['Consecutive_Points'] > 96]\n",
        "count_above_96_60gap = above_96_60gap.shape[0]\n",
        "\n",
        "print(\"Número de falhas com duração maior que 1 dia:\", count_above_96_60gap)\n",
        "print(f\"Isto corresponde a {(count_above_96_60gap*100)/len(missings_gap60_df):.2f}% das falhas\")"
      ],
      "metadata": {
        "id": "AVbFsK8_ng8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "above_96_60gap"
      ],
      "metadata": {
        "id": "nV6jS9ndpEJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "above_192_60gap = missings_gap60_df[missings_gap60_df['Consecutive_Points'] > 192]\n",
        "count_above_192_60gap = above_192_60gap.shape[0]\n",
        "\n",
        "print(\"Número de falhas com duração maior que 2 dias:\", count_above_192_60gap)\n",
        "print(f\"Isto corresponde a {(count_above_192_60gap*100)/len(missings_gap60_df):.2f}% das falhas\")"
      ],
      "metadata": {
        "id": "YNf7lM6Ang80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "above_192_60gap"
      ],
      "metadata": {
        "id": "YY8PR2xUpE1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "less_than_1day = missings_gap30_df[missings_gap30_df['Consecutive_Points'] < 96]\n",
        "\n",
        "yticks_labels = [convert_to_time_less_than_1day(y) for y in [0, 20, 40, 60, 80]]\n",
        "\n",
        "sns.boxplot(data=less_than_1day, whis=100)\n",
        "plt.yticks([0, 20, 40, 60, 80], yticks_labels)\n",
        "plt.title(\"Estudo de Falhas pós normalização com duração menor do que 1 dia\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FCmWWMt73dZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not less_than_1day.empty:\n",
        "    max_index = less_than_1day['Consecutive_Points'].idxmax()\n",
        "    row_with_max_points = less_than_1day.loc[max_index]\n",
        "    print(row_with_max_points)\n",
        "else:\n",
        "    print(\"No rows with Consecutive_Points < 96 found.\")"
      ],
      "metadata": {
        "id": "dtILTA52_vX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(less_than_1day)"
      ],
      "metadata": {
        "id": "OVT_ef93AZiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_intervals = pd.timedelta_range(start='00:00:00', end='23:45:00', freq='5H').astype(str)\n",
        "time_intervals = time_intervals.insert(len(time_intervals), '24:00:00')\n",
        "\n",
        "table_data = pd.DataFrame(columns=['Intervalo de Tempo', 'Número de falhas', 'Número de falhas %*'])\n",
        "\n",
        "for i in range(len(time_intervals) - 1):\n",
        "    start_time = time_intervals[i].split()[-1]\n",
        "    end_time = time_intervals[i + 1].split()[-1]\n",
        "\n",
        "    points_in_interval = less_than_1day[\n",
        "        (less_than_1day['Consecutive_Points'] >= i * 20) & (less_than_1day['Consecutive_Points'] < (i + 1) * 20)\n",
        "    ]\n",
        "\n",
        "    count = len(points_in_interval)\n",
        "    total_points = len(less_than_1day)\n",
        "    percentage = (count / total_points) * 100 if total_points > 0 else 0\n",
        "\n",
        "    table_data.loc[i] = [f'{start_time} <= x < {end_time}', count, f'{percentage:.2f}%']\n",
        "\n",
        "print(table_data)\n",
        "print(\"\\n*% referente ao total de falhas com duração menor que 1 dia\")"
      ],
      "metadata": {
        "id": "RPtDO4W4BeKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "above_96_30gap\n",
        "print(\"Gap de 30 min\")\n",
        "print(f\"A percentagem de falhas superior a 1 dia é de {((len(above_96_30gap)*100)/len(missings_gap30_df)):.2f}%\")\n",
        "print(f\"A percentagem de falhas inferior a 1 dia é de {((len(less_than_1day)*100)/len(missings_gap30_df)):.2f}%\")"
      ],
      "metadata": {
        "id": "6gU9Fu_YIKEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_intervals = pd.timedelta_range(start='00:00:00', end='23:45:00', freq='2H').astype(str)\n",
        "time_intervals = time_intervals.insert(len(time_intervals), '24:00:00')\n",
        "\n",
        "table_data = pd.DataFrame(columns=['Intervalo de Tempo', 'Número de falhas', 'Número de falhas %*'])\n",
        "\n",
        "for i in range(len(time_intervals) - 1):\n",
        "    start_time = time_intervals[i].split()[-1]\n",
        "    end_time = time_intervals[i + 1].split()[-1]\n",
        "\n",
        "    points_in_interval = less_than_1day[\n",
        "        (less_than_1day['Consecutive_Points'] >= i * 8) & (less_than_1day['Consecutive_Points'] < (i + 1) * 8)\n",
        "    ]\n",
        "\n",
        "    count = len(points_in_interval)\n",
        "    total_points = len(less_than_1day)\n",
        "    percentage = (count / total_points) * 100 if total_points > 0 else 0\n",
        "\n",
        "    table_data.loc[i] = [f'{start_time} <= x < {end_time}', count, f'{percentage:.2f}%']\n",
        "print(table_data)\n",
        "print(\"\\n*% referente ao total de falhas com duração menor que 1 dia\")"
      ],
      "metadata": {
        "id": "lv2bGEu2KDJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_to_12h = less_than_1day[less_than_1day['Consecutive_Points'] <= 48].copy()\n",
        "missing_to_12h['Caudal'] = 0\n",
        "print(statistics(missing_to_12h).drop(['Min_Value', 'Max_Value'], axis=1))\n",
        "\n",
        "print(f\"\\nExistem {len(missing_to_12h)} falhas menores que 12h o que corresponde a  {(len(missing_to_12h)*100)/len(max30min_df)}% da amostra\")"
      ],
      "metadata": {
        "id": "Nh7LYVQ3R9b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_from_12h_24h = less_than_1day[less_than_1day['Consecutive_Points'] > 48].copy()\n",
        "missing_from_12h_24h['Caudal'] = 0\n",
        "\n",
        "if len(missing_from_12h_24h) > 0:\n",
        "  print(statistics(missing_from_12h_24h).drop(['Min_Value', 'Max_Value'], axis=1))\n",
        "\n",
        "print(f\"\\nExistem {len(missing_from_12h_24h)} falhas menores que 1 dia e maiores do que 12h o que corresponde a  {(len(missing_from_12h_24h)*100)/len(max30min_df)}% da amostra\")"
      ],
      "metadata": {
        "id": "-4zpTeqxUi71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "more_than_24h = missings_gap30_df[missings_gap30_df['Consecutive_Points'] > 96].copy()\n",
        "more_than_24h['Caudal'] = 0\n",
        "\n",
        "if len(more_than_24h) > 0:\n",
        "  print(statistics(more_than_24h).drop(['Min_Value', 'Max_Value'], axis=1))\n",
        "\n",
        "print(f\"\\nExistem {len(more_than_24h)} falhas maiores que 1 dia o que corresponde a  {(len(more_than_24h)*100)/len(max30min_df)}% da amostra\")\n"
      ],
      "metadata": {
        "id": "l5xhSZeVc9Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_statistics(func, *args, **kwargs):\n",
        "    try:\n",
        "        return func(*args, **kwargs)\n",
        "    except ValueError:\n",
        "        return pd.DataFrame(columns=['Year', 'Month', 'Min_Value', 'Max_Value', 'Count'])\n",
        "\n",
        "stats_df = safe_statistics(statistics, missings_df)\n",
        "stats_outliers_above = safe_statistics(statistics, outliers_above)\n",
        "stats_outliers_below = safe_statistics(statistics, outliers_below)\n",
        "stats_df_normalized = safe_statistics(statistics, missings_normalized)\n",
        "stats_missing_to_12h = safe_statistics(statistics, missing_to_12h)\n",
        "stats_missing_from_12h_24h = safe_statistics(statistics, missing_from_12h_24h)\n",
        "stats_more_than_24h = safe_statistics(statistics, more_than_24h)"
      ],
      "metadata": {
        "id": "aJpJPFvSg2TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def year_month(df):\n",
        "  df['Year_Month'] = df['Year'].astype(str) + '-' + df['Month'].astype(str)\n",
        "  df.set_index('Year_Month', inplace=True)"
      ],
      "metadata": {
        "id": "7l3P4iRP3aiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "year_month(stats_df)\n",
        "year_month(stats_outliers_above)\n",
        "year_month(stats_outliers_below)\n",
        "year_month(stats_df_normalized)\n",
        "year_month(stats_missing_to_12h)\n",
        "year_month(stats_missing_from_12h_24h)\n",
        "year_month(stats_more_than_24h)"
      ],
      "metadata": {
        "id": "V7-FTt6z2GWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_Year_And_Month(df):\n",
        "  df = df.drop(['Year', 'Month'], axis=1)\n",
        "  return df"
      ],
      "metadata": {
        "id": "3hJXm8mh5ity"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_Min_And_Max(df):\n",
        "  df = df.drop(['Min_Value', 'Max_Value'], axis=1)\n",
        "  return df"
      ],
      "metadata": {
        "id": "cGIdcmuw4jE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats_df = drop_Year_And_Month(stats_df)\n",
        "stats_outliers_above = drop_Year_And_Month(stats_outliers_above)\n",
        "stats_outliers_below = drop_Year_And_Month(stats_outliers_below)\n",
        "stats_df_normalized = drop_Year_And_Month(stats_df_normalized)\n",
        "stats_missing_to_12h = drop_Year_And_Month(stats_missing_to_12h)\n",
        "stats_missing_from_12h_24h = drop_Year_And_Month(stats_missing_from_12h_24h)\n",
        "stats_more_than_24h = drop_Year_And_Month(stats_more_than_24h)"
      ],
      "metadata": {
        "id": "BZdjOzbv4vS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats_df = drop_Min_And_Max(stats_df)\n",
        "stats_df_normalized = drop_Min_And_Max(stats_df_normalized)\n",
        "stats_missing_to_12h = drop_Min_And_Max(stats_missing_to_12h)\n",
        "stats_missing_from_12h_24h = drop_Min_And_Max(stats_missing_from_12h_24h)\n",
        "stats_more_than_24h = drop_Min_And_Max(stats_more_than_24h)"
      ],
      "metadata": {
        "id": "IOFsFx9S6jce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.DataFrame()"
      ],
      "metadata": {
        "id": "o4Jsl3zxyKON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = [stats_df, stats_outliers_above, stats_outliers_below, stats_df_normalized, stats_missing_to_12h, stats_missing_from_12h_24h, stats_more_than_24h]\n",
        "\n",
        "merged_df = dfs[0]\n",
        "\n",
        "for i in range(1, len(dfs)):\n",
        "    merged_df = merged_df.merge(dfs[i], left_index=True, right_index=True, how='outer', suffixes=('', f'_df{i}'))\n"
      ],
      "metadata": {
        "id": "UTZtVIRY6pzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.index = pd.to_datetime(merged_df.index, format='%Y-%m')\n",
        "merged_df = merged_df.sort_index()\n",
        "merged_df.index = merged_df.index.to_period('M').astype(str)"
      ],
      "metadata": {
        "id": "HixVBFmQc4fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = merged_df.rename(columns={\n",
        "    'Count': 'série bruta registos sem caudal (%)',\n",
        "    'Min_Value': 'série bruta oultliers de caudal máximo(LI) (m3/h)',\n",
        "    'Max_Value': 'série bruta oultliers de caudal máximo(LS) (m3/h)',\n",
        "    'Count_df1': 'série bruta nº de oultliers de caudal máximo (nº)',\n",
        "    'Min_Value_df2': 'série bruta oultliers de caudal minimo(LI) (m3/h)',\n",
        "    'Max_Value_df2': 'série bruta oultliers de caudal minimo(LS) (m3/h)',\n",
        "    'Count_df2': 'série bruta nº de oultliers de caudal minimo (nº)',\n",
        "    'Count_df3': 'série normalizada valores omissos (%)',\n",
        "    'Count_df4': 'série normalizada falhas com duração inf. 12 h (n.º)',\n",
        "    'Count_df5': 'série normalizada falhas com duração 12 - 24 h (n.º)',\n",
        "    'Count_df6': 'série normalizada falhas com duração sup. 24 h (n.º)'\n",
        "})"
      ],
      "metadata": {
        "id": "cCqf9EaDiys0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['série bruta registos sem caudal (%)'] = (merged_df['série bruta registos sem caudal (%)']*100)/len(df)"
      ],
      "metadata": {
        "id": "_s92m0Id6DRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['série normalizada valores omissos (%)'] = (merged_df['série normalizada valores omissos (%)']*100)/len(max30min_df)"
      ],
      "metadata": {
        "id": "wDO6dvby6W2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df"
      ],
      "metadata": {
        "id": "k8BlLSqGdZwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max30min_df.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "2rzZNsaWrEW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max30min_df = max30min_df.drop(['Year', 'Month'], axis=1)"
      ],
      "metadata": {
        "id": "Bf_7GEDSr68m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_row_time = max30min_df.iloc[0]['Data']\n",
        "if first_row_time.time() != pd.to_datetime('00:00:00').time():\n",
        "    start_time = first_row_time.replace(hour=0, minute=0, second=0, microsecond=0)\n",
        "    end_time = first_row_time\n",
        "\n",
        "    time_range = pd.date_range(start=start_time, end=end_time, freq='15T')\n",
        "\n",
        "    time_range = time_range[time_range < end_time]\n",
        "\n",
        "    new_rows = pd.DataFrame({'Data': time_range, 'Caudal': np.nan})\n",
        "\n",
        "    max30min_df = pd.concat([new_rows, max30min_df]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "Qw02o8p1BTFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max30min_df"
      ],
      "metadata": {
        "id": "UFIifXcmDCDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy1 = max30min_df.copy()"
      ],
      "metadata": {
        "id": "5XNGSbNCdR3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aux = copy1.values"
      ],
      "metadata": {
        "id": "xj-ShY__d09l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matriz = [[None] * 97 for _ in range(1097)]"
      ],
      "metadata": {
        "id": "aUqdZzHE9WzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matriz[0][0] = 'Date'"
      ],
      "metadata": {
        "id": "HLIXqNCf8Fk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(96):\n",
        "  matriz[0][i+1] = aux[i][0].strftime('%H:%M')"
      ],
      "metadata": {
        "id": "mvxtoeBy8Sok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auxlenght = 0\n",
        "for k in range(1096):\n",
        "  first = 0\n",
        "  for j in range(96):\n",
        "    if first == 0:\n",
        "      matriz[k+1][0] = aux[auxlenght][0].strftime('%Y/%m/%d')\n",
        "\n",
        "      if auxlenght + 95 > len(aux):\n",
        "        break\n",
        "\n",
        "    auxlenght += 1\n",
        "    first = 1"
      ],
      "metadata": {
        "id": "J49tCWgDA4Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auxlenght = 0\n",
        "\n",
        "for m in range(1096):\n",
        "  for n in range(96):\n",
        "    if auxlenght >= len(aux):\n",
        "      break\n",
        "\n",
        "    matriz[m+1][n+1] = aux[auxlenght][1]\n",
        "    auxlenght += 1"
      ],
      "metadata": {
        "id": "W2gHRqOUGBat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = matriz[0]\n",
        "\n",
        "data = matriz[1:]\n",
        "\n",
        "rexcel = pd.DataFrame(data, columns=columns)"
      ],
      "metadata": {
        "id": "3mJgv6z8LQ2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rexcel"
      ],
      "metadata": {
        "id": "6hVqoJ5ZjNdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max30min_df.to_excel('normalized.xlsx', index=False)"
      ],
      "metadata": {
        "id": "LwHBIeymd_Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = pd.ExcelWriter('rexcel.xlsx', engine='xlsxwriter')\n",
        "\n",
        "rexcel.to_excel(writer, sheet_name='Sheet1', index=False)\n",
        "\n",
        "workbook  = writer.book\n",
        "worksheet = writer.sheets['Sheet1']\n",
        "\n",
        "header_format = workbook.add_format({})\n",
        "\n",
        "for col_num, value in enumerate(rexcel.columns.values):\n",
        "    worksheet.write(0, col_num, value, header_format)\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "B-3G_eTf1haM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preenchimento de Falhas"
      ],
      "metadata": {
        "id": "Klji7XtelGos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_forecast_Anual = pd.read_csv('data_with_Anual.csv', delimiter=',')"
      ],
      "metadata": {
        "id": "bd98vTp0rhSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_forecast_Anual.loc[0, 'Data'] = '2013-07-01  00:00:00'"
      ],
      "metadata": {
        "id": "d2DJT4BK3YLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_forecast_Anual.isnull().any().any()"
      ],
      "metadata": {
        "id": "Djcy6dcixAxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_forecast_Weekly = pd.read_csv('data_with_Weekly.csv', delimiter=',')"
      ],
      "metadata": {
        "id": "gjil4J1pr89x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_forecast_Weekly.loc[0, 'Data'] = '2013-07-01  00:00:00'"
      ],
      "metadata": {
        "id": "Vpa7hyuy3n_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_forecast_Weekly.isnull().any().any()"
      ],
      "metadata": {
        "id": "ZEypnxPOyH6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_Quevedo = pd.read_csv('Quevedo.csv', delimiter=',')"
      ],
      "metadata": {
        "id": "SvRI-5MKslcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_Quevedo = reconstruct_Quevedo.drop(\"Unnamed: 0\", axis = 1)"
      ],
      "metadata": {
        "id": "MN1daFgVswG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_Quevedo.rename(columns=lambda x: x[1:] if x.startswith('X') else x, inplace=True)"
      ],
      "metadata": {
        "id": "i1fbQtDFtUY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_Quevedo.rename(columns=lambda x: x.replace('.', ':'), inplace=True)"
      ],
      "metadata": {
        "id": "Z4uWgRD6ttKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_long = pd.melt(reconstruct_Quevedo, id_vars=['Date'], var_name='Time', value_name='Caudal')\n",
        "\n",
        "df_long['DateTime'] = pd.to_datetime(df_long['Date'] + ' ' + df_long['Time'], format='%Y/%m/%d %H:%M')\n",
        "\n",
        "df_long = df_long.drop(columns=['Date', 'Time'])\n",
        "\n",
        "df_long = df_long[['DateTime', 'Caudal']]\n",
        "\n",
        "df_long = df_long.sort_values(by='DateTime').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "pKhECh7duPhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_Quevedo = df_long"
      ],
      "metadata": {
        "id": "HP9aNDGpwDqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_Quevedo.isnull().any().any()"
      ],
      "metadata": {
        "id": "s-ifaxQ1yK7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_tbats = pd.read_csv('TBATS.csv', delimiter=',')\n",
        "reconstruct_tbats = reconstruct_tbats.drop(\"Unnamed: 0\", axis = 1)\n",
        "reconstruct_tbats.rename(columns=lambda x: x[1:] if x.startswith('X') else x, inplace=True)\n",
        "reconstruct_tbats.rename(columns=lambda x: x.replace('.', ':'), inplace=True)\n",
        "\n",
        "df_long = pd.melt(reconstruct_tbats, id_vars=['Date'], var_name='Time', value_name='Caudal')\n",
        "\n",
        "df_long['DateTime'] = pd.to_datetime(df_long['Date'] + ' ' + df_long['Time'], format='%Y/%m/%d %H:%M')\n",
        "\n",
        "df_long = df_long.drop(columns=['Date', 'Time'])\n",
        "\n",
        "df_long = df_long[['DateTime', 'Caudal']]\n",
        "\n",
        "df_long = df_long.sort_values(by='DateTime').reset_index(drop=True)\n",
        "\n",
        "reconstruct_tbats = df_long"
      ],
      "metadata": {
        "id": "1Q5MOk7gw-eB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_tbats.isnull().any().any()"
      ],
      "metadata": {
        "id": "44wR2Fnnx_DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TBATS_nan_mask = reconstruct_tbats.isnull().any(axis=1)\n",
        "\n",
        "num_nan_rows = TBATS_nan_mask.sum()\n",
        "print(f\"Number of rows with NaN values: {num_nan_rows}\")\n",
        "\n",
        "nan_rows = reconstruct_tbats[TBATS_nan_mask]\n",
        "print(\"Rows with NaN values:\")\n",
        "print(nan_rows)"
      ],
      "metadata": {
        "id": "0b5Ij6y52fC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_rows = copy1[copy1.isnull().any(axis=1)]"
      ],
      "metadata": {
        "id": "9NeQB82nyQxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions = pd.DataFrame(columns=['Date', 'forecast_Anual', 'forecast_Weekly', 'Quevedo', 'TBATS'])\n",
        "\n",
        "for index in nan_rows.index:\n",
        "    reconstructions.loc[index, 'Date'] = nan_rows.loc[index, 'Data']\n",
        "    reconstructions.loc[index, 'forecast_Anual'] = reconstruct_forecast_Anual.iloc[index]['Caudal']\n",
        "    reconstructions.loc[index, 'forecast_Weekly'] = reconstruct_forecast_Weekly.iloc[index]['Caudal']\n",
        "    reconstructions.loc[index, 'Quevedo'] = reconstruct_Quevedo.iloc[index]['Caudal']\n",
        "    reconstructions.loc[index, 'TBATS'] = reconstruct_tbats.iloc[index]['Caudal']"
      ],
      "metadata": {
        "id": "Zlz6j3rf37Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions"
      ],
      "metadata": {
        "id": "tyMy4F9n9Yq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions['diff_forecast_Anual'] = ((reconstructions['forecast_Anual'] - reconstructions['TBATS']) / reconstructions['TBATS']) * 100\n",
        "reconstructions['diff_forecast_Weekly'] = ((reconstructions['forecast_Weekly'] - reconstructions['TBATS']) / reconstructions['TBATS']) * 100\n",
        "reconstructions['diff_Quevedo'] = ((reconstructions['Quevedo'] - reconstructions['TBATS']) / reconstructions['TBATS']) * 100\n",
        "\n",
        "reconstructions['diff_forecast_Anual'] = reconstructions['diff_forecast_Anual'].abs()\n",
        "reconstructions['diff_forecast_Weekly'] = reconstructions['diff_forecast_Weekly'].abs()\n",
        "reconstructions['diff_Quevedo'] = reconstructions['diff_Quevedo'].abs()\n"
      ],
      "metadata": {
        "id": "jGEW-eRCy1x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_abs_diff_forecast_Anual = reconstructions['diff_forecast_Anual'].mean()\n",
        "median_abs_diff_forecast_Anual = reconstructions['diff_forecast_Anual'].median()\n",
        "\n",
        "mean_abs_diff_forecast_Weekly = reconstructions['diff_forecast_Weekly'].mean()\n",
        "median_abs_diff_forecast_Weekly = reconstructions['diff_forecast_Weekly'].median()\n",
        "\n",
        "mean_abs_diff_Quevedo = reconstructions['diff_Quevedo'].mean()\n",
        "median_abs_diff_Quevedo = reconstructions['diff_Quevedo'].median()\n",
        "\n",
        "print(\"Percentagem de diferença de cada método relativamente ao TBATS:\")\n",
        "print(f\"Forecast com sazonalidade Anual - Média: {mean_abs_diff_forecast_Anual:.2f}%, Mediana: {median_abs_diff_forecast_Anual:.2f}%\")\n",
        "print(f\"Forecast com sazonalidade Semanal - Média: {mean_abs_diff_forecast_Weekly:.2f}%, Mediana: {median_abs_diff_forecast_Weekly:.2f}%\")\n",
        "print(f\"Quevedo - Média: {mean_abs_diff_Quevedo:.2f}%, Mediana: {median_abs_diff_Quevedo:.2f}%\")"
      ],
      "metadata": {
        "id": "8aTxsX-dy9rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(reconstructions['Date'], reconstructions['forecast_Anual'], marker='o', linestyle='-', color='blue', label='forecast_Anual')\n",
        "plt.plot(reconstructions['Date'], reconstructions['forecast_Weekly'], marker='o', linestyle='-', color='red', label='forecast_Weekly')\n",
        "plt.plot(reconstructions['Date'], reconstructions['Quevedo'], marker='o', linestyle='-', color='green', label='Quevedo')\n",
        "plt.plot(reconstructions['Date'], reconstructions['TBATS'], marker='o', linestyle='-', color='purple', label='TBATS')\n",
        "\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Differences')\n",
        "plt.title('Differences Between Values for Each Forecasting Method Over Time')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "30fB9W7j-v4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(reconstructions['Date'], reconstructions['TBATS'], marker='o', linestyle='-', color='purple', label='TBATS')\n",
        "plt.plot(reconstructions['Date'], reconstructions['Quevedo'], marker='o', linestyle='-', color='green', label='Quevedo')\n",
        "\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Differences')\n",
        "plt.title('Differences Between Values for Each Forecasting Method Over Time')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Ep60fedAZ-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions"
      ],
      "metadata": {
        "id": "pkC4-WegAT2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruct_Quevedo"
      ],
      "metadata": {
        "id": "FYko-WGAVnsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df"
      ],
      "metadata": {
        "id": "IexMPU2_D1lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.to_excel('results.xlsx', index=True)"
      ],
      "metadata": {
        "id": "CaXPHau2SEDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Identificação de Eventos Anómalos"
      ],
      "metadata": {
        "id": "OXFcoXGIEDvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Avarias_df = pd.read_excel(\"/content/.xlsx\", sheet_name=\"\")"
      ],
      "metadata": {
        "id": "PD0gUX1xEIQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def datetime_in_range(datetime, start_datetimes, end_datetimes):\n",
        "    for start, end in zip(start_datetimes, end_datetimes):\n",
        "        if start <= datetime <= end:\n",
        "            return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "cgq1syW3wAt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Avarias_df"
      ],
      "metadata": {
        "id": "87A_-4CqEQp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_outlier_above"
      ],
      "metadata": {
        "id": "y5-mX7mCFMiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_outlier_below"
      ],
      "metadata": {
        "id": "y5IoY0V1FO8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_outlier_above['Data'] = pd.to_datetime(original_outlier_above['Data'])\n",
        "original_outlier_below['Data'] = pd.to_datetime(original_outlier_below['Data'])\n",
        "Avarias_df['Data/Hora'] = pd.to_datetime(Avarias_df['Data/Hora'])\n",
        "Avarias_df['Data Conclusão'] = pd.to_datetime(Avarias_df['Data Conclusão'])"
      ],
      "metadata": {
        "id": "cJf8NHC2FfPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_outlier_above['Exists in Avarias_df'] = original_outlier_above['Data'].apply(\n",
        "    lambda datetime: datetime_in_range(datetime, Avarias_df['Data/Hora'], Avarias_df['Data Conclusão'])\n",
        ")\n",
        "\n",
        "original_outlier_below['Exists in Avarias_df'] = original_outlier_below['Data'].apply(\n",
        "    lambda datetime: datetime_in_range(datetime, Avarias_df['Data/Hora'], Avarias_df['Data Conclusão'])\n",
        ")"
      ],
      "metadata": {
        "id": "MExliXqnw7Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_rows_above = original_outlier_above[original_outlier_above['Exists in Avarias_df']]\n",
        "true_rows_below = original_outlier_below[original_outlier_below['Exists in Avarias_df']]"
      ],
      "metadata": {
        "id": "WYWLwk7HGkR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_true_rows = pd.concat([true_rows_above, true_rows_below])\n",
        "combined_true_rows.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "awe2f3ELHqKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_true_rows"
      ],
      "metadata": {
        "id": "yiPhUhC_HuQD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "YHGpeZTxUPbr",
        "8ZHCL0sXYnQJ",
        "mHgGS6rOYqvw",
        "fWt5wpaOYvOg",
        "Vjy6hfiyYyyT",
        "P7pmTjO10uwu",
        "v11C5Uwr0i8i"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyN0r4UyUZ9vX5xzUjxDtITu"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}